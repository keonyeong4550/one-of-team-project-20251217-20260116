version: "3.8"

services:
  ai-core:
    container_name: ai-work-bridge
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    env_file:
      - .env
    # [핵심] 컨테이너 안에서 'host.docker.internal'로 로컬 Ollama 접속 허용
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
